{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drugs_data.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['drug_name', 'uses']]\n",
    "df.to_csv('cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1424 entries, 0 to 1423\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   drug_name  571 non-null    object\n",
      " 1   uses       571 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 22.4+ KB\n",
      "None\n",
      "Final file saved without drug names containing commas or empty values.\n"
     ]
    }
   ],
   "source": [
    "cleaned = pd.read_csv(\"cleaned.csv\")\n",
    "print(cleaned.info())\n",
    "# Remove rows where 'drug_name' contains a comma\n",
    "\n",
    "\n",
    "# Remove rows where 'drug_name' is empty or contains only commas\n",
    "cleaned = cleaned[cleaned['drug_name'].notna()]  # Remove NaN values\n",
    "cleaned = cleaned[~cleaned['drug_name'].str.contains(r'^[, ]*$', na=False)]  # Remove empty/comma-only rows\n",
    "cleaned = cleaned[~cleaned['drug_name'].str.contains(',', na=False)]  # Remove rows where 'drug_name' contains commas\n",
    "\n",
    "# Keep only 'drug_name' and 'summary' columns\n",
    "final_df = cleaned[['drug_name', 'uses']]\n",
    "\n",
    "# Save the cleaned dataset\n",
    "final_df.to_csv('final.csv', index=False)\n",
    "\n",
    "print(\"Final file saved without drug names containing commas or empty values.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           drug_name                                               uses\n",
      "0             Abecma  Abecma is a CAR T cell therapy used to treat r...\n",
      "1            Abilify  Abilify is an antipsychotic medication. It wor...\n",
      "2  Abilify Asimtufii  Abilify Asimtufii is an atypical antipsychotic...\n",
      "3   Abilify Maintena  Abilify Maintena (aripiprazole) extended-relea...\n",
      "4        Abiraterone  Abiraterone works by reducing androgen product...\n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug_name    0\n",
      "uses         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      535.000000\n",
      "mean       673.590654\n",
      "std        881.275116\n",
      "min          9.000000\n",
      "25%        276.000000\n",
      "50%        450.000000\n",
      "75%        760.000000\n",
      "max      12756.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_df[\"text_length\"] = final_df[\"uses\"].dropna().apply(len)\n",
    "print(final_df[\"text_length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average, Max & Min length of 'uses' Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average text length (characters not words): 673.5906542056075\n",
      "Max text legnth (characters not words): 12756\n",
      "Min text legnth (characters not words): 9\n"
     ]
    }
   ],
   "source": [
    "final_df[\"text_length\"] = final_df[\"uses\"].dropna().apply(len)\n",
    "print(\"\\nAverage text length (characters not words):\", final_df['text_length'].mean()) \n",
    "print(\"Max text legnth (characters not words):\", final_df['text_length'].max())\n",
    "print(\"Min text legnth (characters not words):\", final_df['text_length'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs with the Longest 'uses' Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drugs with the longest Description:\n",
      "         drug_name  text_length\n",
      "567        Alcohol        12756\n",
      "1201  Atezolizumab         6701\n",
      "10      Adalimumab         4215\n",
      "311     Adalimumab         4215\n",
      "1029       Arcoxia         3927\n",
      "716       Amjevita         3630\n",
      "111       Abrilada         3578\n",
      "62         Austedo         3290\n",
      "1283       Austedo         3290\n",
      "8          Actemra         2969\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDrugs with the longest Description:\") \n",
    "print(final_df.loc[final_df['text_length'].nlargest(10).index, ['drug_name', 'text_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First10 file created with the first 10 rows!\n"
     ]
    }
   ],
   "source": [
    "# Extract the first 10 rows, bch l'operation te5ou a9al wa9t\n",
    "First10 = final_df.head(10)\n",
    "\n",
    "# Save it to a new CSV file\n",
    "First10.to_csv('First10.csv', index=False)\n",
    "\n",
    "print(\"First10 file created with the first 10 rows!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agood\\AppData\\Local\\Temp\\ipykernel_30996\\1146331443.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  First10['summary'] = First10['uses'].dropna().apply(lambda x: summarize_text(x))\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def summarize_text(text, max_length=80):  # Increased max_length\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"longest\")\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        inputs['input_ids'], \n",
    "        max_length=max_length, \n",
    "        min_length=10,  # Increased min_length\n",
    "        length_penalty=1.0,  # Lowered length penalty\n",
    "        num_beams=4, \n",
    "        early_stopping=False  # Let it generate until it feels complete\n",
    "    )\n",
    "    \n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Apply summarization to 'uses' column and store in a new 'summary' column\n",
    "First10['summary'] = First10['uses'].dropna().apply(lambda x: summarize_text(x))\n",
    "\n",
    "#idha n7ebou ne5dmou dataset lkol, nbadlou First10 par final_df\n",
    "\n",
    "# Save the results to CSV\n",
    "# Keep only 'drug_name' and 'summary' clumns\n",
    "summary = First10[['drug_name', 'summary']]\n",
    "\n",
    "# Save the final dataset\n",
    "summary.to_csv('summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "#model_name = \"facebook/bart-large-cnn\"\n",
    "#tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "#model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "#def summarize_text(text, max_length=40):\n",
    "    # Tokenize input text with truncation\n",
    "   # inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"longest\")\n",
    "    \n",
    "    # Generate summary ids\n",
    "   # summary_ids = model.generate(inputs['input_ids'], max_length=max_length, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    #summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    #return summary\n",
    "\n",
    "# Apply summarization to 'uses' column and store in a new 'summary' column\n",
    "#cleaned['summary'] = cleaned['uses'].dropna().apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Save the results to CSV\n",
    "#cleaned.to_csv('medications_with_summaries.csv', index=False)\n",
    "\n",
    "#print(\"Summarization complete! Check 'medications_with_summaries1.csv' for the results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
